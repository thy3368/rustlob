# SREè¿ç»´é¢†åŸŸèƒ½åŠ›ä½“ç³»

## ç›®å½•

- [1. è¿ç»´èƒ½åŠ›çŸ©é˜µ](#1-è¿ç»´èƒ½åŠ›çŸ©é˜µ)
- [2. å¯é æ€§å·¥ç¨‹](#2-å¯é æ€§å·¥ç¨‹)
- [3. æ€§èƒ½å·¥ç¨‹](#3-æ€§èƒ½å·¥ç¨‹)
- [4. å®‰å…¨è¿ç»´](#4-å®‰å…¨è¿ç»´)
- [5. æˆæœ¬ä¼˜åŒ–](#5-æˆæœ¬ä¼˜åŒ–)
- [6. è‡ªåŠ¨åŒ–è¿ç»´](#6-è‡ªåŠ¨åŒ–è¿ç»´)
- [7. æ··æ²Œå·¥ç¨‹](#7-æ··æ²Œå·¥ç¨‹)
- [8. äº‹ä»¶å“åº”](#8-äº‹ä»¶å“åº”)
- [9. å®¹é‡è§„åˆ’](#9-å®¹é‡è§„åˆ’)
- [10. æœ€ä½³å®è·µæ¡ˆä¾‹](#10-æœ€ä½³å®è·µæ¡ˆä¾‹)

---

## 1. è¿ç»´èƒ½åŠ›çŸ©é˜µ

### 1.1 èƒ½åŠ›æˆç†Ÿåº¦æ¨¡å‹

| èƒ½åŠ›åŸŸ | L1 åŸºç¡€ | L2 æ ‡å‡† | L3 ä¼˜åŒ– | L4 åˆ›æ–° | L5 å¼•é¢† |
|--------|---------|---------|---------|---------|---------|
| **å¯è§‚æµ‹æ€§** | åŸºç¡€ç›‘æ§ | å…¨é“¾è·¯è¿½è¸ª | æ™ºèƒ½å‘Šè­¦ | é¢„æµ‹æ€§ç›‘æ§ | AIOps |
| **è‡ªåŠ¨åŒ–** | è„šæœ¬åŒ– | CI/CD | GitOps | è‡ªæ„ˆç³»ç»Ÿ | è‡ªä¸»è¿ç»´ |
| **å¯é æ€§** | 99% SLA | 99.9% SLA | 99.99% SLA | å®¹é”™è®¾è®¡ | æ··æ²Œå·¥ç¨‹å¸¸æ€åŒ– |
| **å®‰å…¨** | åŸºç¡€è®¤è¯ | RBAC | é›¶ä¿¡ä»» | è‡ªåŠ¨åŒ–å®‰å…¨æ‰«æ | å®‰å…¨å·¦ç§» |
| **æ€§èƒ½** | åŸºç¡€ä¼˜åŒ– | APM | å®æ—¶ä¼˜åŒ– | æ™ºèƒ½è°ƒä¼˜ | è‡ªé€‚åº”ç³»ç»Ÿ |
| **æˆæœ¬** | è´¦å•ç›‘æ§ | æˆæœ¬å½’å›  | è‡ªåŠ¨ä¼˜åŒ– | FinOps | å…¨å±€æˆæœ¬ä¼˜åŒ– |

### 1.2 æ ¸å¿ƒèƒ½åŠ›åœ°å›¾

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      SRE æ ¸å¿ƒèƒ½åŠ›ä½“ç³»           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                       â”‚
        v                       v                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¯é æ€§å·¥ç¨‹    â”‚      â”‚  æ€§èƒ½å·¥ç¨‹      â”‚      â”‚  å®‰å…¨è¿ç»´      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - SLO/SLI     â”‚      â”‚ - æ€§èƒ½åŸºçº¿     â”‚      â”‚ - èº«ä»½è®¤è¯     â”‚
â”‚ - æ•…éšœé¢„é˜²     â”‚      â”‚ - ç“¶é¢ˆåˆ†æ     â”‚      â”‚ - æƒé™ç®¡ç†     â”‚
â”‚ - å®¹é”™è®¾è®¡     â”‚      â”‚ - è‡ªåŠ¨è°ƒä¼˜     â”‚      â”‚ - æ¼æ´æ‰«æ     â”‚
â”‚ - ç¾éš¾æ¢å¤     â”‚      â”‚ - å‹æµ‹         â”‚      â”‚ - åˆè§„å®¡è®¡     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                       â”‚
        v                       v                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æˆæœ¬ä¼˜åŒ–      â”‚      â”‚  è‡ªåŠ¨åŒ–è¿ç»´    â”‚      â”‚  æ··æ²Œå·¥ç¨‹      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - èµ„æºä¼˜åŒ–     â”‚      â”‚ - IaC         â”‚      â”‚ - æ•…éšœæ³¨å…¥     â”‚
â”‚ - æˆæœ¬å½’å›      â”‚      â”‚ - è‡ªæ„ˆç³»ç»Ÿ     â”‚      â”‚ - éŸ§æ€§æµ‹è¯•     â”‚
â”‚ - FinOps      â”‚      â”‚ - æ™ºèƒ½è°ƒåº¦     â”‚      â”‚ - æ¼”ç»ƒ         â”‚
â”‚ - ROIåˆ†æ     â”‚      â”‚ - è‡ªåŠ¨æ‰©ç¼©å®¹   â”‚      â”‚ - å¼±ç‚¹å‘ç°     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. å¯é æ€§å·¥ç¨‹

### 2.1 SLO/SLIä½“ç³»è®¾è®¡

#### 2.1.1 SLIæŒ‡æ ‡å®šä¹‰

```rust
// src/domain/entities/reliability/sli.rs

/// æœåŠ¡çº§åˆ«æŒ‡æ ‡(SLI)
pub struct ServiceLevelIndicator {
    pub id: SliId,
    pub name: String,
    pub service: ServiceId,
    pub metric: SliMetric,
    pub measurement_window: Duration,
    pub calculation_method: CalculationMethod,
}

pub enum SliMetric {
    /// å¯ç”¨æ€§: æˆåŠŸè¯·æ±‚æ¯”ä¾‹
    Availability {
        success_criteria: SuccessCriteria,
    },
    /// å»¶è¿Ÿ: P99å»¶è¿Ÿ
    Latency {
        threshold: Duration,
        percentile: f64,
    },
    /// é”™è¯¯ç‡
    ErrorRate {
        max_error_rate: f64,
    },
    /// ååé‡
    Throughput {
        min_requests_per_second: f64,
    },
    /// æ•°æ®ä¸€è‡´æ€§
    Correctness {
        validation_rules: Vec<ValidationRule>,
    },
}

pub enum SuccessCriteria {
    /// HTTPçŠ¶æ€ç 
    HttpStatus { accepted_codes: Vec<u16> },
    /// gRPCçŠ¶æ€ç 
    GrpcStatus { accepted_codes: Vec<i32> },
    /// è‡ªå®šä¹‰ä¸šåŠ¡è§„åˆ™
    Custom { predicate: Box<dyn Fn(&Response) -> bool> },
}

impl ServiceLevelIndicator {
    /// è®¡ç®—SLIå½“å‰å€¼
    pub fn calculate(&self, metrics: &[Metric]) -> Result<f64, SliError> {
        match &self.metric {
            SliMetric::Availability { success_criteria } => {
                let total = metrics.len() as f64;
                let successful = metrics.iter()
                    .filter(|m| success_criteria.is_success(m))
                    .count() as f64;
                Ok(successful / total * 100.0)
            }
            SliMetric::Latency { threshold, percentile } => {
                let latencies: Vec<f64> = metrics.iter()
                    .map(|m| m.latency.as_secs_f64())
                    .collect();
                let p_value = calculate_percentile(&latencies, *percentile);
                Ok((p_value < threshold.as_secs_f64()) as u8 as f64 * 100.0)
            }
            SliMetric::ErrorRate { .. } => {
                let total = metrics.len() as f64;
                let errors = metrics.iter()
                    .filter(|m| m.is_error())
                    .count() as f64;
                Ok((1.0 - errors / total) * 100.0)
            }
            _ => unimplemented!(),
        }
    }
}
```

#### 2.1.2 SLOç›®æ ‡å®šä¹‰

```rust
// src/domain/entities/reliability/slo.rs

/// æœåŠ¡çº§åˆ«ç›®æ ‡(SLO)
pub struct ServiceLevelObjective {
    pub id: SloId,
    pub name: String,
    pub service: ServiceId,
    pub sli: SliId,
    pub target: f64,  // ç›®æ ‡å€¼ (ä¾‹å¦‚ 99.9%)
    pub time_window: TimeWindow,
    pub error_budget: ErrorBudget,
    pub alert_thresholds: Vec<AlertThreshold>,
}

pub enum TimeWindow {
    Rolling { duration: Duration },
    Calendar { period: CalendarPeriod },
}

pub enum CalendarPeriod {
    Daily,
    Weekly,
    Monthly,
    Quarterly,
}

pub struct ErrorBudget {
    pub remaining: f64,
    pub consumed: f64,
    pub total: f64,
    pub burn_rate: f64,  // å½“å‰æ¶ˆè€—é€Ÿç‡
}

impl ServiceLevelObjective {
    /// è®¡ç®—é”™è¯¯é¢„ç®—
    pub fn calculate_error_budget(&self, current_sli: f64) -> ErrorBudget {
        let total_budget = 100.0 - self.target;
        let consumed = 100.0 - current_sli;
        let remaining = total_budget - consumed;
        let burn_rate = consumed / self.time_window.as_hours() as f64;

        ErrorBudget {
            remaining,
            consumed,
            total: total_budget,
            burn_rate,
        }
    }

    /// æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
    pub fn should_alert(&self, error_budget: &ErrorBudget) -> Option<AlertLevel> {
        for threshold in &self.alert_thresholds {
            if error_budget.burn_rate > threshold.burn_rate_threshold {
                return Some(threshold.alert_level.clone());
            }
        }
        None
    }

    /// æ˜¯å¦åº”è¯¥åœæ­¢å‘å¸ƒ
    pub fn should_freeze_deployments(&self, error_budget: &ErrorBudget) -> bool {
        error_budget.remaining < 10.0  // å‰©ä½™ä¸è¶³10%
    }
}

pub struct AlertThreshold {
    pub burn_rate_threshold: f64,
    pub alert_level: AlertLevel,
    pub notification_channels: Vec<NotificationChannel>,
}

pub enum AlertLevel {
    Info,
    Warning,
    Critical,
}
```

#### 2.1.3 SLOé…ç½®ç¤ºä¾‹

```yaml
# config/slos/payment-service.yaml
apiVersion: sre.example.com/v1
kind: ServiceLevelObjective
metadata:
  name: payment-service-availability
  namespace: production
spec:
  service: payment-service
  description: "Payment service availability SLO"

  # SLIå®šä¹‰
  sli:
    metric: availability
    successCriteria:
      httpStatusCodes: [200, 201, 202]
    measurementWindow: 5m

  # SLOç›®æ ‡
  target: 99.95  # 99.95% å¯ç”¨æ€§
  timeWindow:
    type: rolling
    duration: 30d

  # å‘Šè­¦é˜ˆå€¼
  alerting:
    # å¿«é€Ÿburn rateï¼ˆ5åˆ†é’Ÿçª—å£ï¼‰
    - window: 5m
      burnRateThreshold: 14.4  # 1å°æ—¶å†…è€—å°½é”™è¯¯é¢„ç®—
      severity: critical
      notificationChannels:
        - pagerduty-critical

    # ä¸­é€Ÿburn rateï¼ˆ1å°æ—¶çª—å£ï¼‰
    - window: 1h
      burnRateThreshold: 6.0  # 5å°æ—¶å†…è€—å°½
      severity: warning
      notificationChannels:
        - slack-sre-team

    # æ…¢é€Ÿburn rateï¼ˆ6å°æ—¶çª—å£ï¼‰
    - window: 6h
      burnRateThreshold: 1.0  # 30å¤©æ­£å¸¸æ¶ˆè€—
      severity: info
      notificationChannels:
        - email-team

  # é”™è¯¯é¢„ç®—ç­–ç•¥
  errorBudgetPolicy:
    # å‰©ä½™é¢„ç®— < 10% æ—¶å†»ç»“éç´§æ€¥å‘å¸ƒ
    freezeDeploymentsThreshold: 10
    # å‰©ä½™é¢„ç®— < 5% æ—¶å›æ»šæœ€è¿‘å‘å¸ƒ
    autoRollbackThreshold: 5

---
apiVersion: sre.example.com/v1
kind: ServiceLevelObjective
metadata:
  name: payment-service-latency
  namespace: production
spec:
  service: payment-service
  description: "Payment service P99 latency SLO"

  sli:
    metric: latency
    percentile: 99
    threshold: 500ms
    measurementWindow: 5m

  target: 99.0  # 99% çš„è¯·æ±‚ < 500ms
  timeWindow:
    type: rolling
    duration: 30d

  alerting:
    - window: 5m
      burnRateThreshold: 10.0
      severity: warning
      notificationChannels:
        - slack-sre-team
```

### 2.2 æ•…éšœé¢„é˜²æœºåˆ¶

#### 2.2.1 é¢„å˜æ›´å½±å“åˆ†æ

```rust
// src/application/usecases/reliability/change_impact_analysis.rs

pub struct ChangeImpactAnalyzer {
    dependency_graph: Arc<ServiceDependencyGraph>,
    historical_incidents: Arc<dyn IncidentRepository>,
    slo_calculator: Arc<dyn SloCalculator>,
}

impl ChangeImpactAnalyzer {
    /// åˆ†æå˜æ›´çš„æ½œåœ¨å½±å“
    pub async fn analyze_change_impact(
        &self,
        change: &Change,
    ) -> Result<ImpactAnalysisReport, AnalysisError> {
        // 1. è¯†åˆ«å—å½±å“çš„æœåŠ¡
        let affected_services = self.identify_affected_services(change).await?;

        // 2. è®¡ç®—å½±å“èŒƒå›´
        let blast_radius = self.calculate_blast_radius(&affected_services).await?;

        // 3. åˆ†æå†å²é£é™©
        let historical_risk = self.analyze_historical_risk(change).await?;

        // 4. è¯„ä¼°SLOå½±å“
        let slo_impact = self.assess_slo_impact(&affected_services).await?;

        // 5. ç”Ÿæˆå»ºè®®
        let recommendations = self.generate_recommendations(
            &blast_radius,
            &historical_risk,
            &slo_impact,
        );

        Ok(ImpactAnalysisReport {
            change_id: change.id.clone(),
            affected_services,
            blast_radius,
            historical_risk,
            slo_impact,
            recommendations,
            risk_score: self.calculate_risk_score(&blast_radius, &historical_risk),
        })
    }

    async fn identify_affected_services(
        &self,
        change: &Change,
    ) -> Result<Vec<ServiceId>, AnalysisError> {
        let mut affected = vec![change.target_service.clone()];

        // è¯†åˆ«ä¸‹æ¸¸ä¾èµ–
        let downstream = self.dependency_graph
            .downstream_services(&change.target_service)
            .await?;

        affected.extend(downstream);

        // è¯†åˆ«å…±äº«èµ„æºä¾èµ–
        let shared_resources = self.dependency_graph
            .shared_resources(&change.target_service)
            .await?;

        for resource in shared_resources {
            let consumers = self.dependency_graph
                .resource_consumers(&resource)
                .await?;
            affected.extend(consumers);
        }

        Ok(affected)
    }

    async fn calculate_blast_radius(
        &self,
        services: &[ServiceId],
    ) -> Result<BlastRadius, AnalysisError> {
        let total_services = self.dependency_graph.total_services().await?;
        let affected_percentage = (services.len() as f64 / total_services as f64) * 100.0;

        let total_traffic = self.get_total_traffic().await?;
        let affected_traffic: f64 = services.iter()
            .map(|s| self.get_service_traffic(s))
            .sum::<f64>()
            .await?;
        let traffic_percentage = (affected_traffic / total_traffic) * 100.0;

        Ok(BlastRadius {
            affected_services: services.len(),
            affected_percentage,
            affected_traffic,
            traffic_percentage,
            critical_services: self.identify_critical_services(services).await?,
        })
    }

    async fn analyze_historical_risk(
        &self,
        change: &Change,
    ) -> Result<HistoricalRisk, AnalysisError> {
        // æŸ¥è¯¢ç±»ä¼¼å˜æ›´çš„å†å²äº‹æ•…
        let similar_changes = self.historical_incidents
            .find_similar_changes(change)
            .await?;

        let incident_rate = similar_changes.iter()
            .filter(|c| c.caused_incident)
            .count() as f64 / similar_changes.len() as f64;

        let mean_time_to_detect = similar_changes.iter()
            .filter_map(|c| c.time_to_detect)
            .sum::<Duration>()
            / similar_changes.len() as u32;

        let mean_time_to_resolve = similar_changes.iter()
            .filter_map(|c| c.time_to_resolve)
            .sum::<Duration>()
            / similar_changes.len() as u32;

        Ok(HistoricalRisk {
            similar_changes_count: similar_changes.len(),
            incident_rate,
            mean_time_to_detect,
            mean_time_to_resolve,
            common_failure_modes: self.identify_common_failures(&similar_changes),
        })
    }

    fn generate_recommendations(
        &self,
        blast_radius: &BlastRadius,
        historical_risk: &HistoricalRisk,
        slo_impact: &SloImpact,
    ) -> Vec<Recommendation> {
        let mut recommendations = Vec::new();

        // æ ¹æ®å½±å“èŒƒå›´æ¨èç­–ç•¥
        if blast_radius.affected_percentage > 50.0 {
            recommendations.push(Recommendation {
                priority: Priority::High,
                action: "ä½¿ç”¨è“ç»¿éƒ¨ç½²ç­–ç•¥ï¼Œç¡®ä¿å¯å¿«é€Ÿå›æ»š".to_string(),
            });
        }

        if blast_radius.critical_services.len() > 0 {
            recommendations.push(Recommendation {
                priority: Priority::Critical,
                action: "å½±å“å…³é”®æœåŠ¡ï¼Œå»ºè®®åœ¨ä½å³°æœŸè¿›è¡Œå˜æ›´".to_string(),
            });
        }

        // æ ¹æ®å†å²é£é™©æ¨è
        if historical_risk.incident_rate > 0.1 {
            recommendations.push(Recommendation {
                priority: Priority::High,
                action: format!(
                    "ç±»ä¼¼å˜æ›´å†å²äº‹æ•…ç‡{:.1}%ï¼Œå»ºè®®å¢åŠ æµ‹è¯•è¦†ç›–",
                    historical_risk.incident_rate * 100.0
                ),
            });
        }

        // æ ¹æ®SLOå½±å“æ¨è
        if slo_impact.error_budget_at_risk {
            recommendations.push(Recommendation {
                priority: Priority::Critical,
                action: "å½“å‰é”™è¯¯é¢„ç®—ä¸è¶³ï¼Œå»ºè®®æ¨è¿Ÿéç´§æ€¥å˜æ›´".to_string(),
            });
        }

        recommendations
    }
}
```

#### 2.2.2 è‡ªåŠ¨åŒ–é‡‘ä¸é›€åˆ†æ

```rust
// src/application/usecases/reliability/canary_analysis.rs

pub struct AutomatedCanaryAnalyzer {
    metrics_repo: Arc<dyn MetricRepository>,
    statistical_analyzer: Arc<dyn StatisticalAnalyzer>,
    slo_calculator: Arc<dyn SloCalculator>,
}

impl AutomatedCanaryAnalyzer {
    /// è‡ªåŠ¨åˆ†æé‡‘ä¸é›€éƒ¨ç½²å¥åº·çŠ¶å†µ
    pub async fn analyze_canary(
        &self,
        deployment: &Deployment,
        canary_percentage: u8,
    ) -> Result<CanaryAnalysisResult, AnalysisError> {
        let baseline_metrics = self.collect_baseline_metrics(deployment).await?;
        let canary_metrics = self.collect_canary_metrics(deployment).await?;

        // 1. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
        let statistical_comparison = self.statistical_analyzer
            .compare_distributions(&baseline_metrics, &canary_metrics)
            .await?;

        // 2. SLOåˆè§„æ€§æ£€æŸ¥
        let slo_compliance = self.check_slo_compliance(&canary_metrics).await?;

        // 3. å¼‚å¸¸æ£€æµ‹
        let anomalies = self.detect_anomalies(&canary_metrics, &baseline_metrics).await?;

        // 4. ç»¼åˆè¯„åˆ†
        let health_score = self.calculate_health_score(
            &statistical_comparison,
            &slo_compliance,
            &anomalies,
        );

        let verdict = self.make_verdict(health_score, &anomalies);

        Ok(CanaryAnalysisResult {
            deployment_id: deployment.id.clone(),
            canary_percentage,
            statistical_comparison,
            slo_compliance,
            anomalies,
            health_score,
            verdict,
            recommendation: self.generate_recommendation(&verdict, &anomalies),
        })
    }

    async fn compare_distributions(
        &self,
        baseline: &[Metric],
        canary: &[Metric],
    ) -> Result<StatisticalComparison, AnalysisError> {
        // Mann-Whitney Uæ£€éªŒï¼ˆéå‚æ•°æ£€éªŒï¼‰
        let latency_pvalue = self.mann_whitney_u_test(
            &baseline.iter().map(|m| m.latency).collect::<Vec<_>>(),
            &canary.iter().map(|m| m.latency).collect::<Vec<_>>(),
        )?;

        // å¡æ–¹æ£€éªŒï¼ˆé”™è¯¯ç‡ï¼‰
        let error_rate_pvalue = self.chi_square_test(
            baseline.iter().filter(|m| m.is_error()).count(),
            baseline.len(),
            canary.iter().filter(|m| m.is_error()).count(),
            canary.len(),
        )?;

        Ok(StatisticalComparison {
            latency_difference: LatencyDifference {
                baseline_p99: calculate_percentile(&baseline, 0.99),
                canary_p99: calculate_percentile(&canary, 0.99),
                pvalue: latency_pvalue,
                is_significant: latency_pvalue < 0.05,
            },
            error_rate_difference: ErrorRateDifference {
                baseline_rate: self.calculate_error_rate(baseline),
                canary_rate: self.calculate_error_rate(canary),
                pvalue: error_rate_pvalue,
                is_significant: error_rate_pvalue < 0.05,
            },
        })
    }

    fn make_verdict(
        &self,
        health_score: f64,
        anomalies: &[Anomaly],
    ) -> CanaryVerdict {
        if health_score >= 90.0 && anomalies.is_empty() {
            CanaryVerdict::Pass
        } else if health_score >= 70.0 && anomalies.iter().all(|a| a.severity != Severity::Critical) {
            CanaryVerdict::Marginal
        } else {
            CanaryVerdict::Fail {
                reasons: self.collect_failure_reasons(anomalies),
            }
        }
    }
}
```

### 2.3 å®¹é”™è®¾è®¡æ¨¡å¼

#### 2.3.1 æ–­è·¯å™¨æ¨¡å¼

```rust
// src/infrastructure/resilience/circuit_breaker.rs

use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};

pub struct CircuitBreaker {
    state: Arc<Mutex<CircuitBreakerState>>,
    config: CircuitBreakerConfig,
    metrics: Arc<Mutex<CircuitBreakerMetrics>>,
}

pub struct CircuitBreakerConfig {
    pub failure_threshold: u32,
    pub success_threshold: u32,
    pub timeout: Duration,
    pub half_open_max_calls: u32,
}

struct CircuitBreakerState {
    status: CircuitStatus,
    failure_count: u32,
    success_count: u32,
    last_failure_time: Option<Instant>,
    half_open_calls: u32,
}

pub enum CircuitStatus {
    Closed,
    Open,
    HalfOpen,
}

impl CircuitBreaker {
    pub fn new(config: CircuitBreakerConfig) -> Self {
        Self {
            state: Arc::new(Mutex::new(CircuitBreakerState {
                status: CircuitStatus::Closed,
                failure_count: 0,
                success_count: 0,
                last_failure_time: None,
                half_open_calls: 0,
            })),
            config,
            metrics: Arc::new(Mutex::new(CircuitBreakerMetrics::default())),
        }
    }

    pub async fn call<F, T, E>(&self, operation: F) -> Result<T, CircuitBreakerError>
    where
        F: FnOnce() -> Result<T, E> + Send,
        E: std::error::Error,
    {
        // æ£€æŸ¥æ–­è·¯å™¨çŠ¶æ€
        if !self.allow_request()? {
            return Err(CircuitBreakerError::Open);
        }

        // æ‰§è¡Œæ“ä½œ
        let start = Instant::now();
        let result = operation();
        let duration = start.elapsed();

        // è®°å½•ç»“æœ
        match result {
            Ok(value) => {
                self.record_success(duration);
                Ok(value)
            }
            Err(e) => {
                self.record_failure(duration);
                Err(CircuitBreakerError::CallFailed(e.to_string()))
            }
        }
    }

    fn allow_request(&self) -> Result<bool, CircuitBreakerError> {
        let mut state = self.state.lock().unwrap();

        match state.status {
            CircuitStatus::Closed => Ok(true),
            CircuitStatus::Open => {
                // æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›å…¥åŠå¼€çŠ¶æ€
                if let Some(last_failure) = state.last_failure_time {
                    if last_failure.elapsed() > self.config.timeout {
                        state.status = CircuitStatus::HalfOpen;
                        state.half_open_calls = 0;
                        Ok(true)
                    } else {
                        Ok(false)
                    }
                } else {
                    Ok(false)
                }
            }
            CircuitStatus::HalfOpen => {
                // åŠå¼€çŠ¶æ€é™åˆ¶å¹¶å‘è¯·æ±‚æ•°
                if state.half_open_calls < self.config.half_open_max_calls {
                    state.half_open_calls += 1;
                    Ok(true)
                } else {
                    Ok(false)
                }
            }
        }
    }

    fn record_success(&self, duration: Duration) {
        let mut state = self.state.lock().unwrap();
        let mut metrics = self.metrics.lock().unwrap();

        metrics.record_success(duration);

        match state.status {
            CircuitStatus::HalfOpen => {
                state.success_count += 1;
                if state.success_count >= self.config.success_threshold {
                    // æ¢å¤åˆ°å…³é—­çŠ¶æ€
                    state.status = CircuitStatus::Closed;
                    state.failure_count = 0;
                    state.success_count = 0;
                    tracing::info!("Circuit breaker closed");
                }
            }
            CircuitStatus::Closed => {
                state.failure_count = 0;
            }
            _ => {}
        }
    }

    fn record_failure(&self, duration: Duration) {
        let mut state = self.state.lock().unwrap();
        let mut metrics = self.metrics.lock().unwrap();

        metrics.record_failure(duration);
        state.last_failure_time = Some(Instant::now());

        match state.status {
            CircuitStatus::HalfOpen => {
                // åŠå¼€çŠ¶æ€å¤±è´¥åˆ™ç«‹å³æ‰“å¼€
                state.status = CircuitStatus::Open;
                state.failure_count = 0;
                state.success_count = 0;
                tracing::warn!("Circuit breaker opened from half-open state");
            }
            CircuitStatus::Closed => {
                state.failure_count += 1;
                if state.failure_count >= self.config.failure_threshold {
                    state.status = CircuitStatus::Open;
                    tracing::warn!("Circuit breaker opened");
                }
            }
            _ => {}
        }
    }

    pub fn metrics(&self) -> CircuitBreakerMetrics {
        self.metrics.lock().unwrap().clone()
    }
}

#[derive(Clone, Default)]
pub struct CircuitBreakerMetrics {
    pub total_calls: u64,
    pub successful_calls: u64,
    pub failed_calls: u64,
    pub rejected_calls: u64,
    pub avg_response_time: Duration,
}
```

#### 2.3.2 é‡è¯•ä¸é€€é¿ç­–ç•¥

```rust
// src/infrastructure/resilience/retry.rs

pub struct RetryPolicy {
    pub max_attempts: u32,
    pub backoff_strategy: BackoffStrategy,
    pub retryable_errors: Vec<ErrorType>,
}

pub enum BackoffStrategy {
    Fixed { interval: Duration },
    Linear { initial: Duration, increment: Duration },
    Exponential { initial: Duration, multiplier: f64, max: Duration },
    ExponentialWithJitter { initial: Duration, multiplier: f64, max: Duration },
}

impl BackoffStrategy {
    pub fn calculate_delay(&self, attempt: u32) -> Duration {
        match self {
            Self::Fixed { interval } => *interval,
            Self::Linear { initial, increment } => {
                *initial + *increment * attempt
            }
            Self::Exponential { initial, multiplier, max } => {
                let delay = initial.as_millis() as f64 * multiplier.powi(attempt as i32);
                Duration::from_millis(delay.min(max.as_millis() as f64) as u64)
            }
            Self::ExponentialWithJitter { initial, multiplier, max } => {
                let base_delay = initial.as_millis() as f64 * multiplier.powi(attempt as i32);
                let jitter = rand::random::<f64>() * base_delay * 0.1;  // Â±10% jitter
                let delay = base_delay + jitter;
                Duration::from_millis(delay.min(max.as_millis() as f64) as u64)
            }
        }
    }
}

pub async fn retry_with_policy<F, T, E>(
    policy: &RetryPolicy,
    operation: F,
) -> Result<T, E>
where
    F: Fn() -> Pin<Box<dyn Future<Output = Result<T, E>> + Send>>,
    E: std::error::Error,
{
    let mut attempt = 0;

    loop {
        attempt += 1;

        match operation().await {
            Ok(result) => return Ok(result),
            Err(error) => {
                if attempt >= policy.max_attempts {
                    tracing::error!("Max retry attempts reached: {}", attempt);
                    return Err(error);
                }

                if !policy.is_retryable(&error) {
                    tracing::warn!("Non-retryable error encountered");
                    return Err(error);
                }

                let delay = policy.backoff_strategy.calculate_delay(attempt);
                tracing::warn!(
                    "Retry attempt {} after {:?}: {}",
                    attempt,
                    delay,
                    error
                );

                tokio::time::sleep(delay).await;
            }
        }
    }
}
```

---

## 3. æ€§èƒ½å·¥ç¨‹

### 3.1 æ€§èƒ½åŸºçº¿å»ºç«‹

```rust
// src/application/usecases/performance/baseline_calculator.rs

pub struct PerformanceBaselineCalculator {
    metrics_repo: Arc<dyn MetricRepository>,
    statistical_analyzer: Arc<dyn StatisticalAnalyzer>,
}

impl PerformanceBaselineCalculator {
    /// è®¡ç®—æœåŠ¡æ€§èƒ½åŸºçº¿
    pub async fn calculate_baseline(
        &self,
        service: &ServiceId,
        time_range: &TimeRange,
    ) -> Result<PerformanceBaseline, CalculationError> {
        // æ”¶é›†å†å²æŒ‡æ ‡æ•°æ®
        let metrics = self.metrics_repo
            .query_service_metrics(service, time_range)
            .await?;

        // è¿‡æ»¤å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
        let filtered_metrics = self.filter_outliers(&metrics);

        // è®¡ç®—å„ç»´åº¦åŸºçº¿
        let latency_baseline = self.calculate_latency_baseline(&filtered_metrics)?;
        let throughput_baseline = self.calculate_throughput_baseline(&filtered_metrics)?;
        let error_rate_baseline = self.calculate_error_rate_baseline(&filtered_metrics)?;
        let resource_baseline = self.calculate_resource_baseline(&filtered_metrics)?;

        Ok(PerformanceBaseline {
            service: service.clone(),
            calculated_at: Timestamp::now(),
            time_range: time_range.clone(),
            sample_size: filtered_metrics.len(),
            latency: latency_baseline,
            throughput: throughput_baseline,
            error_rate: error_rate_baseline,
            resources: resource_baseline,
        })
    }

    fn calculate_latency_baseline(
        &self,
        metrics: &[Metric],
    ) -> Result<LatencyBaseline, CalculationError> {
        let latencies: Vec<f64> = metrics.iter()
            .map(|m| m.latency.as_secs_f64())
            .collect();

        Ok(LatencyBaseline {
            p50: calculate_percentile(&latencies, 0.50),
            p95: calculate_percentile(&latencies, 0.95),
            p99: calculate_percentile(&latencies, 0.99),
            p999: calculate_percentile(&latencies, 0.999),
            mean: latencies.iter().sum::<f64>() / latencies.len() as f64,
            stddev: self.statistical_analyzer.standard_deviation(&latencies),
        })
    }

    fn filter_outliers(&self, metrics: &[Metric]) -> Vec<Metric> {
        let latencies: Vec<f64> = metrics.iter()
            .map(|m| m.latency.as_secs_f64())
            .collect();

        let q1 = calculate_percentile(&latencies, 0.25);
        let q3 = calculate_percentile(&latencies, 0.75);
        let iqr = q3 - q1;
        let lower_bound = q1 - 1.5 * iqr;
        let upper_bound = q3 + 1.5 * iqr;

        metrics.iter()
            .filter(|m| {
                let latency = m.latency.as_secs_f64();
                latency >= lower_bound && latency <= upper_bound
            })
            .cloned()
            .collect()
    }
}

pub struct PerformanceBaseline {
    pub service: ServiceId,
    pub calculated_at: Timestamp,
    pub time_range: TimeRange,
    pub sample_size: usize,
    pub latency: LatencyBaseline,
    pub throughput: ThroughputBaseline,
    pub error_rate: ErrorRateBaseline,
    pub resources: ResourceBaseline,
}

pub struct LatencyBaseline {
    pub p50: f64,
    pub p95: f64,
    pub p99: f64,
    pub p999: f64,
    pub mean: f64,
    pub stddev: f64,
}
```

### 3.2 è‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•

```yaml
# k6-load-test.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: k6-load-test
  namespace: performance
spec:
  template:
    spec:
      containers:
        - name: k6
          image: grafana/k6:latest
          args:
            - run
            - --out
            - influxdb=http://influxdb.performance.svc:8086/k6
            - /scripts/load-test.js
          env:
            - name: TARGET_URL
              value: "http://my-service.production.svc"
            - name: VUS
              value: "100"  # è™šæ‹Ÿç”¨æˆ·æ•°
            - name: DURATION
              value: "5m"
          volumeMounts:
            - name: scripts
              mountPath: /scripts
      volumes:
        - name: scripts
          configMap:
            name: k6-scripts
      restartPolicy: Never
```

```javascript
// k6-scripts/load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate, Trend } from 'k6/metrics';

// è‡ªå®šä¹‰æŒ‡æ ‡
const errorRate = new Rate('errors');
const latencyTrend = new Trend('latency');

export const options = {
  stages: [
    { duration: '1m', target: 50 },   // çˆ¬å¡
    { duration: '3m', target: 100 },  // ç¨³å®šè´Ÿè½½
    { duration: '1m', target: 200 },  // å³°å€¼è´Ÿè½½
    { duration: '1m', target: 0 },    // ä¸‹é™
  ],
  thresholds: {
    'http_req_duration': ['p(95)<500', 'p(99)<1000'],  // 95% < 500ms
    'errors': ['rate<0.01'],  // é”™è¯¯ç‡ < 1%
  },
};

export default function () {
  const payload = JSON.stringify({
    userId: `user_${__VU}`,
    action: 'purchase',
    amount: Math.random() * 1000,
  });

  const params = {
    headers: {
      'Content-Type': 'application/json',
    },
    tags: {
      name: 'PaymentAPI',
    },
  };

  const response = http.post(
    `${__ENV.TARGET_URL}/api/v1/payment`,
    payload,
    params
  );

  // æ£€æŸ¥å“åº”
  const success = check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });

  errorRate.add(!success);
  latencyTrend.add(response.timings.duration);

  sleep(1);
}

export function handleSummary(data) {
  return {
    '/tmp/summary.json': JSON.stringify(data),
    'stdout': textSummary(data, { indent: ' ', enableColors: true }),
  };
}
```

---

## 4. å®‰å…¨è¿ç»´

### 4.1 é›¶ä¿¡ä»»æ¶æ„å®ç°

```yaml
# istio-authorization-policies.yaml
# é»˜è®¤æ‹’ç»æ‰€æœ‰æµé‡
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: deny-all
  namespace: production
spec:
  {}  # ç©ºè§„åˆ™ = æ‹’ç»æ‰€æœ‰

---
# å…è®¸ç‰¹å®šæœåŠ¡é—´é€šä¿¡
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: frontend-to-backend
  namespace: production
spec:
  selector:
    matchLabels:
      app: backend-service
  action: ALLOW
  rules:
    - from:
        - source:
            principals: ["cluster.local/ns/production/sa/frontend-service"]
      to:
        - operation:
            methods: ["GET", "POST"]
            paths: ["/api/v1/*"]
      when:
        - key: request.auth.claims[role]
          values: ["service-account"]

---
# JWTéªŒè¯
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: jwt-auth
  namespace: production
spec:
  selector:
    matchLabels:
      app: backend-service
  jwtRules:
    - issuer: "https://auth.example.com"
      jwksUri: "https://auth.example.com/.well-known/jwks.json"
      audiences:
        - "backend-service"
```

### 4.2 è‡ªåŠ¨åŒ–å®‰å…¨æ‰«æ

```yaml
# trivy-scan-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: trivy-security-scan
  namespace: security
spec:
  schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: trivy
              image: aquasec/trivy:latest
              args:
                - image
                - --format
                - json
                - --output
                - /reports/scan-result.json
                - --severity
                - CRITICAL,HIGH
                - your-registry/your-image:latest
              volumeMounts:
                - name: reports
                  mountPath: /reports
          volumes:
            - name: reports
              persistentVolumeClaim:
                claimName: security-reports
          restartPolicy: OnFailure
```

---

## 5. æˆæœ¬ä¼˜åŒ–

### 5.1 èµ„æºå³sizing

```rust
// src/application/usecases/cost/resource_optimizer.rs

pub struct ResourceOptimizer {
    metrics_repo: Arc<dyn MetricRepository>,
    cost_calculator: Arc<dyn CostCalculator>,
}

impl ResourceOptimizer {
    pub async fn analyze_resource_usage(
        &self,
        service: &ServiceId,
        time_range: &TimeRange,
    ) -> Result<OptimizationRecommendation, OptimizerError> {
        // æ”¶é›†èµ„æºä½¿ç”¨æŒ‡æ ‡
        let cpu_usage = self.metrics_repo
            .query_cpu_usage(service, time_range)
            .await?;

        let memory_usage = self.metrics_repo
            .query_memory_usage(service, time_range)
            .await?;

        // è®¡ç®—P95ä½¿ç”¨ç‡
        let cpu_p95 = calculate_percentile(&cpu_usage, 0.95);
        let memory_p95 = calculate_percentile(&memory_usage, 0.95);

        // å½“å‰èµ„æºé…ç½®
        let current_resources = self.get_current_resources(service).await?;

        // è®¡ç®—æ¨èé…ç½®ï¼ˆP95 + 20%ç¼“å†²ï¼‰
        let recommended_cpu = (cpu_p95 * 1.2).ceil() as u32;
        let recommended_memory = (memory_p95 * 1.2).ceil() as u32;

        // è®¡ç®—æˆæœ¬èŠ‚çœ
        let current_cost = self.cost_calculator
            .calculate_monthly_cost(&current_resources)
            .await?;

        let optimized_resources = ResourceSpec {
            cpu: recommended_cpu,
            memory: recommended_memory,
        };

        let optimized_cost = self.cost_calculator
            .calculate_monthly_cost(&optimized_resources)
            .await?;

        Ok(OptimizationRecommendation {
            service: service.clone(),
            current_resources,
            recommended_resources: optimized_resources,
            current_cost,
            optimized_cost,
            potential_savings: current_cost - optimized_cost,
            confidence: self.calculate_confidence(&cpu_usage, &memory_usage),
        })
    }
}
```

---

## 6. æ··æ²Œå·¥ç¨‹

### 6.1 Chaos Meshå®éªŒ

```yaml
# chaos-experiments/network-delay.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay-experiment
  namespace: chaos-testing
spec:
  action: delay
  mode: one
  selector:
    namespaces:
      - production
    labelSelectors:
      app: payment-service
  delay:
    latency: "100ms"
    correlation: "50"
    jitter: "10ms"
  duration: "5m"
  scheduler:
    cron: "@every 1h"

---
# Podå¤±è´¥æ³¨å…¥
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-failure-experiment
  namespace: chaos-testing
spec:
  action: pod-failure
  mode: fixed-percent
  value: "10"  # 10% Podså¤±è´¥
  selector:
    namespaces:
      - production
    labelSelectors:
      app: backend-service
  duration: "2m"

---
# å‹åŠ›æµ‹è¯•
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: cpu-stress-experiment
  namespace: chaos-testing
spec:
  mode: one
  selector:
    namespaces:
      - production
    labelSelectors:
      app: data-processor
  stressors:
    cpu:
      workers: 4
      load: 80
  duration: "10m"
```

---

## 10. æœ€ä½³å®è·µæ¡ˆä¾‹

### 10.1 æ¡ˆä¾‹1ï¼šå¤§è§„æ¨¡å¾®æœåŠ¡å¯è§‚æµ‹æ€§

**åœºæ™¯**: 1000+å¾®æœåŠ¡ï¼Œæ—¥å¤„ç†10äº¿+è¯·æ±‚

**æŒ‘æˆ˜**:
- æµ·é‡æŒ‡æ ‡å­˜å‚¨æˆæœ¬é«˜
- å…¨é“¾è·¯è¿½è¸ªé‡‡æ ·ç‡ä½å¯¼è‡´é—®é¢˜éš¾å¤ç°
- å‘Šè­¦é£æš´éš¾ä»¥å¤„ç†

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# åˆ†å±‚é‡‡æ ·ç­–ç•¥
sampling:
  # é»˜è®¤é‡‡æ ·ç‡1%
  default: 0.01

  # é”™è¯¯è¯·æ±‚100%é‡‡æ ·
  rules:
    - condition: status_code >= 500
      rate: 1.0

    # æ…¢è¯·æ±‚100%é‡‡æ ·
    - condition: duration > 1s
      rate: 1.0

    # VIPç”¨æˆ·10%é‡‡æ ·
    - condition: user_tier == "premium"
      rate: 0.1

# æŒ‡æ ‡èšåˆç­–ç•¥
aggregation:
  # 5åˆ†é’Ÿèšåˆçª—å£
  window: 5m

  # åªä¿ç•™å…³é”®ç»´åº¦
  dimensions:
    - service
    - endpoint
    - status_code

  # é¢„èšåˆå¸¸ç”¨æŸ¥è¯¢
  materialized_views:
    - name: service_error_rate_5m
      query: |
        sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
        /
        sum(rate(http_requests_total[5m])) by (service)
```

**æ•ˆæœ**:
- å­˜å‚¨æˆæœ¬é™ä½70%
- å…³é”®é—®é¢˜è¿½è¸ªè¦†ç›–ç‡è¾¾åˆ°100%
- å‘Šè­¦å™ªéŸ³é™ä½85%

### 10.2 æ¡ˆä¾‹2ï¼šé›¶åœæœºæ•°æ®åº“è¿ç§»

**åœºæ™¯**: PostgreSQLå•æœºè¿ç§»è‡³Auroraé›†ç¾¤

**æ–¹æ¡ˆ**:
1. **åŒå†™é˜¶æ®µ**ï¼ˆWeek 1-2ï¼‰
   ```rust
   pub async fn write_order(&self, order: Order) -> Result<(), Error> {
       // ä¸»åº“å†™å…¥
       self.primary_db.insert_order(&order).await?;

       // æ–°åº“å¼‚æ­¥å†™å…¥
       let new_db = self.new_db.clone();
       let order_clone = order.clone();
       tokio::spawn(async move {
           if let Err(e) = new_db.insert_order(&order_clone).await {
               tracing::error!("Failed to write to new DB: {}", e);
           }
       });

       Ok(())
   }
   ```

2. **æ•°æ®æ ¡éªŒ**ï¼ˆWeek 3ï¼‰
   - å®šæ—¶ä»»åŠ¡å¯¹æ¯”ä¸¤ä¸ªæ•°æ®åº“æ•°æ®ä¸€è‡´æ€§
   - è‡ªåŠ¨ä¿®å¤ä¸ä¸€è‡´æ•°æ®

3. **æµé‡åˆ‡æ¢**ï¼ˆWeek 4ï¼‰
   - ä½¿ç”¨ç‰¹æ€§å¼€å…³é€æ­¥åˆ‡æ¢è¯»æµé‡
   - é‡‘ä¸é›€å‘å¸ƒï¼š5% -> 25% -> 50% -> 100%

4. **å›æ»šé¢„æ¡ˆ**
   - ä¸€é”®åˆ‡å›æ—§åº“çš„è„šæœ¬
   - å®æ—¶ç›‘æ§SLOæŒ‡æ ‡

**æ•ˆæœ**:
- âœ… é›¶åœæœºå®Œæˆè¿ç§»
- âœ… æ€§èƒ½æå‡3å€
- âœ… æˆæœ¬é™ä½40%

---

## æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†é˜è¿°äº†SREè¿ç»´é¢†åŸŸçš„æ ¸å¿ƒèƒ½åŠ›ä½“ç³»ï¼š

1. **å¯é æ€§å·¥ç¨‹**: SLO/SLIã€æ•…éšœé¢„é˜²ã€å®¹é”™è®¾è®¡
2. **æ€§èƒ½å·¥ç¨‹**: åŸºçº¿å»ºç«‹ã€æ€§èƒ½æµ‹è¯•ã€æŒç»­ä¼˜åŒ–
3. **å®‰å…¨è¿ç»´**: é›¶ä¿¡ä»»æ¶æ„ã€è‡ªåŠ¨åŒ–æ‰«æã€åˆè§„å®¡è®¡
4. **æˆæœ¬ä¼˜åŒ–**: èµ„æºå³sizingã€FinOpså®è·µ
5. **è‡ªåŠ¨åŒ–è¿ç»´**: IaCã€è‡ªæ„ˆç³»ç»Ÿã€æ™ºèƒ½è°ƒåº¦
6. **æ··æ²Œå·¥ç¨‹**: éŸ§æ€§æµ‹è¯•ã€æ•…éšœæ¼”ç»ƒ
7. **äº‹ä»¶å“åº”**: å¿«é€Ÿå®šä½ã€æ ¹å› åˆ†æã€è‡ªåŠ¨ä¿®å¤

é€šè¿‡è¿™äº›èƒ½åŠ›çš„ç³»ç»ŸåŒ–å»ºè®¾ï¼Œå¯å®ç°ï¼š
- ğŸ¯ 99.99%+ æœåŠ¡å¯ç”¨æ€§
- âš¡ MTTR < 5åˆ†é’Ÿ
- ğŸ’° æˆæœ¬é™ä½30%+
- ğŸš€ éƒ¨ç½²é¢‘ç‡æå‡10å€+

**æŒç»­æ”¹è¿›æ–¹å‘**:
- AIé©±åŠ¨çš„æ™ºèƒ½è¿ç»´ï¼ˆAIOpsï¼‰
- æ›´ç²¾ç»†çš„æˆæœ¬ä¼˜åŒ–ç­–ç•¥
- å…¨æ ˆå¯è§‚æµ‹æ€§è¦†ç›–
- è‡ªåŠ¨åŒ–éŸ§æ€§æµ‹è¯•

å¸Œæœ›è¿™å¥—ä½“ç³»èƒ½å¸®åŠ©å›¢é˜Ÿæ„å»ºä¸–ç•Œçº§çš„SREèƒ½åŠ›ï¼
