过程宏：检查结构体缓存友好性

我将设计一个过程宏来分析结构体是否缓存友好，并提供优化建议。

1. 基本实现 - 分析字段大小和对齐

// Cargo.toml
// [lib]
// proc-macro = true
// [dependencies]
// proc-macro2 = "1.0"
// quote = "1.0"
// syn = { version = "2.0", features = ["full", "extra-traits"] }

// lib.rs
extern crate proc_macro;
use proc_macro::TokenStream;
use quote::quote;
use syn::{parse_macro_input, DeriveInput, Data, Fields};
use std::collections::HashMap;

#[proc_macro_derive(CacheFriendly, attributes(cache))]
pub fn cache_friendly_derive(input: TokenStream) -> TokenStream {
let ast = parse_macro_input!(input as DeriveInput);
let name = &ast.ident;

    let analysis = analyze_struct(&ast);
    
    let output = quote! {
        impl #name {
            #analysis
        }
    };
    
    output.into()
}

fn analyze_struct(ast: &DeriveInput) -> proc_macro2::TokenStream {
let name = &ast.ident;
let mut field_sizes = Vec::new();
let mut field_alignments = Vec::new();
let mut field_names = Vec::new();
let mut field_types = Vec::new();

    if let Data::Struct(data_struct) = &ast.data {
        if let Fields::Named(fields_named) = &data_struct.fields {
            for field in &fields_named.named {
                let field_name = field.ident.as_ref().unwrap();
                let field_type = &field.ty;
                
                field_names.push(field_name.to_string());
                field_types.push(quote! { #field_type });
                
                // 计算字段大小和对齐（运行时计算）
                let size_code = quote! {
                    std::mem::size_of::<#field_type>()
                };
                let align_code = quote! {
                    std::mem::align_of::<#field_type>()
                };
                
                field_sizes.push(size_code);
                field_alignments.push(align_code);
            }
        }
    }
    
    quote! {
        /// 检查结构体缓存友好性
        pub fn analyze_cache_friendly() -> CacheReport {
            let mut report = CacheReport::new(stringify!(#name));
            
            // 收集字段信息
            let field_names = vec![#(#field_names),*];
            let sizes: Vec<usize> = vec![#(#field_sizes),*];
            let aligns: Vec<usize> = vec![#(#field_alignments),*];
            
            // 分析当前布局
            report.total_size = std::mem::size_of::<#name>();
            report.alignment = std::mem::align_of::<#name>();
            report.field_count = field_names.len();
            
            // 计算填充字节
            report.calculate_padding(&field_names, &sizes, &aligns);
            
            // 检查是否重新排序会更好
            report.check_optimal_ordering(&field_names, &sizes, &aligns);
            
            // 检查是否适合缓存行
            report.check_cache_line_fit();
            
            report
        }
        
        /// 获取内存布局信息
        pub fn memory_layout() -> LayoutInfo {
            LayoutInfo {
                name: stringify!(#name).to_string(),
                size: std::mem::size_of::<#name>(),
                alignment: std::mem::align_of::<#name>(),
                is_packed: false,
            }
        }
    }
}


2. 完整缓存分析宏

// 更完整的实现
use syn::{Attribute, Meta, NestedMeta};
use proc_macro2::Span;
use std::cmp::Ordering;

#[proc_macro_derive(CacheAnalyzer, attributes(cache))]
pub fn cache_analyzer_derive(input: TokenStream) -> TokenStream {
let ast = parse_macro_input!(input as DeriveInput);

    // 解析属性
    let cache_size = parse_cache_attributes(&ast.attrs);
    
    // 生成分析代码
    let expanded = impl_cache_analyzer(&ast, cache_size);
    
    TokenStream::from(expanded)
}

fn parse_cache_attributes(attrs: &[Attribute]) -> Option<usize> {
for attr in attrs {
if attr.path.is_ident("cache") {
if let Ok(Meta::List(meta_list)) = attr.parse_meta() {
for nested in meta_list.nested {
if let NestedMeta::Meta(Meta::NameValue(name_value)) = nested {
if name_value.path.is_ident("line_size") {
if let syn::Lit::Int(lit_int) = name_value.lit {
return lit_int.base10_parse().ok();
}
}
}
}
}
}
}
None
}

fn impl_cache_analyzer(ast: &DeriveInput, cache_line_size: Option<usize>) -> proc_macro2::TokenStream {
let name = &ast.ident;
let cache_line = cache_line_size.unwrap_or(64);

    // 收集字段信息
    let mut fields_info = Vec::new();
    
    if let Data::Struct(data_struct) = &ast.data {
        if let Fields::Named(fields_named) = &data_struct.fields {
            for (i, field) in fields_named.named.iter().enumerate() {
                let field_name = field.ident.as_ref().unwrap();
                let field_type = &field.ty;
                let offset = i; // 简化的偏移计算
                
                fields_info.push(FieldInfo {
                    name: field_name.to_string(),
                    ty: field_type.clone(),
                    idx: i,
                    offset,
                });
            }
        }
    }
    
    // 生成字段分析代码
    let field_analyses: Vec<_> = fields_info.iter().map(|info| {
        let field_name = &info.name;
        let field_type = &info.ty;
        let idx = info.idx;
        
        quote! {
            FieldAnalysis {
                name: #field_name.to_string(),
                offset: #idx, // 简化，实际需要更复杂的计算
                size: std::mem::size_of::<#field_type>(),
                alignment: std::mem::align_of::<#field_type>(),
                is_hot: false, // 可以通过属性标记热点字段
            }
        }
    }).collect();
    
    quote! {
        impl #name {
            /// 详细的缓存分析报告
            pub fn detailed_cache_analysis() -> DetailedCacheReport {
                let field_analyses = vec![
                    #(#field_analyses),*
                ];
                
                let total_size = std::mem::size_of::<Self>();
                let alignment = std::mem::align_of::<Self>();
                
                // 计算各种指标
                let cache_lines_needed = (total_size + #cache_line - 1) / #cache_line;
                
                // 分析字段排序
                let optimal_order = Self::calculate_optimal_field_order(&field_analyses);
                let current_order: Vec<usize> = (0..field_analyses.len()).collect();
                let is_optimal = Self::is_order_optimal(&current_order, &optimal_order, &field_analyses);
                
                // 计算填充
                let padding = Self::calculate_padding(&field_analyses);
                let padding_percentage = (padding as f32 / total_size as f32) * 100.0;
                
                DetailedCacheReport {
                    struct_name: stringify!(#name).to_string(),
                    total_size,
                    alignment,
                    cache_line_size: #cache_line,
                    cache_lines_needed,
                    field_count: field_analyses.len(),
                    field_analyses,
                    padding_bytes: padding,
                    padding_percentage,
                    optimal_field_order: optimal_order,
                    is_current_order_optimal: is_optimal,
                    suggestions: Vec::new(),
                }
            }
            
            /// 计算最优字段顺序
            fn calculate_optimal_field_order(fields: &[FieldAnalysis]) -> Vec<usize> {
                let mut indices: Vec<usize> = (0..fields.len()).collect();
                
                // 按大小和对齐降序排序
                indices.sort_by(|&a, &b| {
                    let field_a = &fields[a];
                    let field_b = &fields[b];
                    
                    // 首先按对齐降序
                    let align_cmp = field_b.alignment.cmp(&field_a.alignment);
                    if align_cmp != Ordering::Equal {
                        return align_cmp;
                    }
                    
                    // 然后按大小降序
                    field_b.size.cmp(&field_a.size)
                });
                
                indices
            }
            
            /// 检查当前顺序是否最优
            fn is_order_optimal(current: &[usize], optimal: &[usize], fields: &[FieldAnalysis]) -> bool {
                if current.len() != optimal.len() {
                    return false;
                }
                
                // 比较排序后的字段大小序列
                let mut current_sizes: Vec<usize> = current.iter()
                    .map(|&idx| fields[idx].size)
                    .collect();
                let mut optimal_sizes: Vec<usize> = optimal.iter()
                    .map(|&idx| fields[idx].size)
                    .collect();
                
                current_sizes.sort_by(|a, b| b.cmp(a));
                optimal_sizes.sort_by(|a, b| b.cmp(a));
                
                current_sizes == optimal_sizes
            }
            
            /// 计算填充字节
            fn calculate_padding(fields: &[FieldAnalysis]) -> usize {
                let mut offset = 0;
                let mut total_padding = 0;
                
                for field in fields {
                    // 计算对齐需要的填充
                    let padding = (field.alignment - (offset % field.alignment)) % field.alignment;
                    total_padding += padding;
                    offset += padding + field.size;
                }
                
                total_padding
            }
            
            /// 生成优化建议
            pub fn optimization_suggestions() -> Vec<String> {
                let mut suggestions = Vec::new();
                let report = Self::detailed_cache_analysis();
                
                if report.padding_percentage > 20.0 {
                    suggestions.push(format!(
                        "结构体 {} 有 {:.1}% 的填充空间，考虑重新排列字段",
                        report.struct_name, report.padding_percentage
                    ));
                }
                
                if !report.is_current_order_optimal {
                    suggestions.push("当前字段顺序不是最优的，建议按照对齐和大小降序排列".to_string());
                }
                
                if report.total_size > 64 {
                    suggestions.push(format!(
                        "结构体大小 {} 字节超过常见缓存行大小(64字节)，考虑拆分",
                        report.total_size
                    ));
                }
                
                if report.cache_lines_needed > 1 {
                    suggestions.push(format!(
                        "需要访问 {} 个缓存行，考虑优化布局",
                        report.cache_lines_needed
                    ));
                }
                
                suggestions
            }
        }
        
        // 相关结构体定义
        #[derive(Debug)]
        pub struct FieldAnalysis {
            pub name: String,
            pub offset: usize,
            pub size: usize,
            pub alignment: usize,
            pub is_hot: bool,
        }
        
        #[derive(Debug)]
        pub struct DetailedCacheReport {
            pub struct_name: String,
            pub total_size: usize,
            pub alignment: usize,
            pub cache_line_size: usize,
            pub cache_lines_needed: usize,
            pub field_count: usize,
            pub field_analyses: Vec<FieldAnalysis>,
            pub padding_bytes: usize,
            pub padding_percentage: f32,
            pub optimal_field_order: Vec<usize>,
            pub is_current_order_optimal: bool,
            pub suggestions: Vec<String>,
        }
        
        #[derive(Debug)]
        pub struct LayoutInfo {
            pub name: String,
            pub size: usize,
            pub alignment: usize,
            pub is_packed: bool,
        }
        
        #[derive(Debug)]
        pub struct CacheReport {
            pub struct_name: String,
            pub total_size: usize,
            pub alignment: usize,
            pub field_count: usize,
            pub padding_bytes: usize,
            pub padding_percentage: f32,
            pub suggestions: Vec<String>,
        }
        
        impl CacheReport {
            fn new(name: &str) -> Self {
                Self {
                    struct_name: name.to_string(),
                    total_size: 0,
                    alignment: 0,
                    field_count: 0,
                    padding_bytes: 0,
                    padding_percentage: 0.0,
                    suggestions: Vec::new(),
                }
            }
            
            fn calculate_padding(&mut self, field_names: &[String], sizes: &[usize], aligns: &[usize]) {
                // 计算填充逻辑
            }
            
            fn check_optimal_ordering(&mut self, field_names: &[String], sizes: &[usize], aligns: &[usize]) {
                // 检查最优顺序
            }
            
            fn check_cache_line_fit(&mut self) {
                // 检查缓存行适应度
            }
        }
    }
}


3. 使用示例

// 在用户代码中使用
use my_macros::CacheAnalyzer;

// 基本使用
#[derive(CacheAnalyzer)]
struct Particle {
x: f32,
y: f32,
z: f32,
velocity_x: f32,
velocity_y: f32,
velocity_z: f32,
mass: f64,
id: u64,
active: bool,
}

// 指定缓存行大小
#[derive(CacheAnalyzer)]
#[cache(line_size = 128)]
struct DataBlock {
timestamp: u64,
values: [f32; 16],
metadata: [u8; 32],
checksum: u32,
}

fn main() {
// 分析结构体
let report = Particle::detailed_cache_analysis();
println!("{:#?}", report);

    // 获取优化建议
    let suggestions = Particle::optimization_suggestions();
    for suggestion in suggestions {
        println!("建议: {}", suggestion);
    }
    
    // 检查特定结构体
    analyze_struct::<Particle>();
}

// 通用分析函数
fn analyze_struct<T>()
where
T: Sized + 'static,
{
let size = std::mem::size_of::<T>();
let align = std::mem::align_of::<T>();
let cache_lines = (size + 63) / 64; // 64字节缓存行

    println!("结构体大小: {} 字节", size);
    println!("对齐要求: {} 字节", align);
    println!("需要缓存行数: {}", cache_lines);
    
    if size > 64 {
        println!("警告: 结构体超过一个缓存行，可能产生缓存行分割");
    }
    
    if size % 64 == 0 {
        println!("良好: 结构体大小正好是缓存行的倍数");
    }
}


4. 高级功能 - 热点字段分析

// 扩展宏以支持热点字段标记
#[proc_macro_derive(CacheOptimized, attributes(hot, cold, align))]
pub fn cache_optimized_derive(input: TokenStream) -> TokenStream {
let ast = parse_macro_input!(input as DeriveInput);

    let expanded = impl_cache_optimized(&ast);
    
    TokenStream::from(expanded)
}

fn impl_cache_optimized(ast: &DeriveInput) -> proc_macro2::TokenStream {
let name = &ast.ident;
let mut hot_fields = Vec::new();
let mut cold_fields = Vec::new();
let mut align_fields = Vec::new();

    if let Data::Struct(data_struct) = &ast.data {
        if let Fields::Named(fields_named) = &data_struct.fields {
            for field in &fields_named.named {
                let field_name = field.ident.as_ref().unwrap();
                let field_type = &field.ty;
                
                // 检查字段属性
                let mut is_hot = false;
                let mut is_cold = false;
                let mut custom_align = None;
                
                for attr in &field.attrs {
                    if attr.path.is_ident("hot") {
                        is_hot = true;
                    } else if attr.path.is_ident("cold") {
                        is_cold = true;
                    } else if attr.path.is_ident("align") {
                        if let Ok(Meta::NameValue(name_value)) = attr.parse_meta() {
                            if let syn::Lit::Int(lit_int) = name_value.lit {
                                custom_align = lit_int.base10_parse::<usize>().ok();
                            }
                        }
                    }
                }
                
                if is_hot {
                    hot_fields.push((field_name, field_type));
                } else if is_cold {
                    cold_fields.push((field_name, field_type));
                }
                
                if let Some(align) = custom_align {
                    align_fields.push((field_name, field_type, align));
                }
            }
        }
    }
    
    // 生成优化建议
    let hot_analysis = if !hot_fields.is_empty() {
        let field_names: Vec<_> = hot_fields.iter().map(|(name, _)| name).collect();
        quote! {
            format!("热点字段: {}", vec![#(#field_names),*].join(", "))
        }
    } else {
        quote! { "无热点字段标记".to_string() }
    };
    
    // 生成优化布局
    quote! {
        impl #name {
            pub fn cache_optimized_layout() -> OptimizedLayout {
                let current_size = std::mem::size_of::<Self>();
                let current_align = std::mem::align_of::<Self>();
                
                // 生成优化建议
                let hot_info = #hot_analysis;
                
                // 计算可能的节约
                let mut potential_savings = 0;
                
                OptimizedLayout {
                    current_size,
                    current_align,
                    hot_fields_info: hot_info,
                    potential_savings,
                    recommendations: vec![
                        "将频繁访问的字段放在一起".to_string(),
                        "考虑使用 #[repr(C)] 控制布局".to_string(),
                        "大数组考虑单独存储".to_string(),
                    ],
                }
            }
            
            /// 生成对比不同布局的性能测试代码
            #[cfg(feature = "bench")]
            pub fn generate_benchmark() -> String {
                let name_str = stringify!(#name);
                format!(
                    r#"
                    criterion_group!(benches, bench_{0});
                    criterion_main!(benches);
                    
                    fn bench_{0}(c: &mut Criterion) {{
                        let mut group = c.benchmark_group("{0}_layout");
                        
                        // 测试当前布局
                        group.bench_function("current", |b| {{
                            let data = vec![{0}::default(); 1000];
                            b.iter(|| {{
                                let mut sum = 0.0;
                                for item in &data {{
                                    black_box(&item);
                                }}
                                sum
                            }})
                        }});
                        
                        // 测试优化布局
                        group.bench_function("optimized", |b| {{
                            let data = vec![Optimized{0}::default(); 1000];
                            b.iter(|| {{
                                let mut sum = 0.0;
                                for item in &data {{
                                    black_box(&item);
                                }}
                                sum
                            }})
                        }});
                        
                        group.finish();
                    }}
                    "#,
                    name_str.to_lowercase()
                )
            }
        }
        
        #[derive(Debug)]
        pub struct OptimizedLayout {
            pub current_size: usize,
            pub current_align: usize,
            pub hot_fields_info: String,
            pub potential_savings: usize,
            pub recommendations: Vec<String>,
        }
    }
}


5. 实际使用示例

// 使用我们定义的宏
use my_cache_macros::{CacheAnalyzer, CacheOptimized};

// 标记热点字段
#[derive(CacheOptimized)]
struct UserProfile {
#[hot]  // 频繁访问
id: u64,
#[hot]  // 频繁访问
username: String,
#[hot]  // 频繁访问
email: String,

    #[cold]  // 不常访问
    registration_date: String,
    #[cold]  // 不常访问
    bio: String,
    
    #[align(64)]  // 对齐到缓存行
    preferences: [u8; 256],
    
    last_login: u64,
    login_count: u32,
    is_active: bool,
    // 7字节填充
}

// 自动生成分析
#[derive(CacheAnalyzer)]
struct DataPacket {
header: PacketHeader,
payload: [u8; 1024],
checksum: u32,
timestamp: u64,
priority: u8,
// 3字节填充
}

// 使用分析功能
fn main() {
// 分析 UserProfile
let profile_report = UserProfile::cache_optimized_layout();
println!("UserProfile 分析:");
println!("当前大小: {} 字节", profile_report.current_size);
println!("热点字段: {}", profile_report.hot_fields_info);
println!("建议:");
for rec in &profile_report.recommendations {
println!("  - {}", rec);
}

    // 分析 DataPacket
    let packet_analysis = DataPacket::detailed_cache_analysis();
    
    println!("\nDataPacket 缓存分析:");
    println!("总大小: {} 字节", packet_analysis.total_size);
    println!("填充: {} 字节 ({:.1}%)", 
        packet_analysis.padding_bytes, 
        packet_analysis.padding_percentage
    );
    println!("需要缓存行: {}", packet_analysis.cache_lines_needed);
    
    if !packet_analysis.is_current_order_optimal {
        println!("警告: 字段顺序不是最优!");
        println!("建议顺序: {:?}", packet_analysis.optimal_field_order);
    }
    
    // 生成优化后的结构体定义
    generate_optimized_struct::<DataPacket>();
}

// 生成优化建议的结构体
fn generate_optimized_struct<T: CacheAnalyzer>() -> String {
let report = T::detailed_cache_analysis();

    let mut code = String::new();
    code.push_str(&format!("// 优化后的 {} 结构体\n", report.struct_name));
    code.push_str(&format!("// 原大小: {} 字节, 优化后估计: {} 字节\n", 
        report.total_size, 
        report.total_size - report.padding_bytes
    ));
    code.push_str("#[repr(C)]\n");
    code.push_str(&format!("pub struct Optimized{} {{\n", report.struct_name));
    
    // 按最优顺序添加字段
    for &idx in &report.optimal_field_order {
        let field = &report.field_analyses[idx];
        code.push_str(&format!("    pub {}: /* 类型 */,\n", field.name));
    }
    
    code.push_str("}\n");
    code
}


6. 高级分析功能

// 扩展功能：自动检测缓存不友好模式
trait CachePatternDetector {
fn detect_patterns(&self) -> Vec<CachePattern>;
}

#[derive(Debug, Clone)]
enum CachePattern {
FalseSharing { field1: String, field2: String },
CacheLineSplit { field: String, split_point: usize },
ExcessivePadding { percentage: f32 },
LargeGap { before: String, after: String, size: usize },
HotColdMix { hot_fields: Vec<String>, cold_fields: Vec<String> },
}

// 在宏中实现模式检测
fn detect_cache_patterns(report: &DetailedCacheReport) -> Vec<CachePattern> {
let mut patterns = Vec::new();

    // 检测伪共享
    if report.total_size > 64 {
        for i in 0..report.field_analyses.len() {
            for j in (i + 1)..report.field_analyses.len() {
                let field1 = &report.field_analyses[i];
                let field2 = &report.field_analyses[j];
                
                // 如果两个字段在不同缓存行但被频繁同时访问
                let line1 = field1.offset / 64;
                let line2 = field2.offset / 64;
                
                if line1 != line2 && (field1.is_hot && field2.is_hot) {
                    patterns.push(CachePattern::FalseSharing {
                        field1: field1.name.clone(),
                        field2: field2.name.clone(),
                    });
                }
            }
        }
    }
    
    // 检测过大填充
    if report.padding_percentage > 30.0 {
        patterns.push(CachePattern::ExcessivePadding {
            percentage: report.padding_percentage,
        });
    }
    
    patterns
}


这个完整的过程宏系统可以：

1. 分析结构体布局 - 计算大小、对齐、填充
2. 检测热点字段 - 通过属性标记
3. 生成优化建议 - 包括字段重排序
4. 检测常见问题 - 伪共享、缓存行分割等
5. 生成优化代码 - 自动生成优化后的结构体定义
6. 性能分析 - 生成基准测试代码

使用时，开发者只需添加 #[derive(CacheAnalyzer)] 到结构体，就能获得详细的缓存友好性分析报告。