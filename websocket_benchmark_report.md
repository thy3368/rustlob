# WebSocket 服务器性能基准测试报告

## 概述

本报告展示了对两个 WebSocket 服务器实现的性能比较：
1. **Axum 服务器** - 使用 axum 框架的内置 WebSocket 支持
2. **Sockudo 服务器** - 使用 sockudo-ws 高性能 WebSocket 库

测试环境：
- 硬件：Apple M1 Pro (10核心 CPU, 32GB RAM)
- 操作系统：macOS Sonoma 14.6
- Rust 版本：1.75.0 (release 模式, -O3 优化)
- 测试时间：2024年1月7日

## 测试配置

### 延迟测试 (Latency Test)
- 测试方法：单连接往返时间测量
- 采样数量：1000个样本
- 测量时间：每个服务器30秒
- 消息大小：小消息（JSON格式）

### 吞吐量测试 (Throughput Test)
- 测试方法：并发连接和消息发送
- 并发连接数：100个
- 每个连接发送消息数：1000条
- 消息内容：{"text": "Hello from connection X - message Y"}
- 测量时间：每个服务器30秒

## 测试结果

### 1. 延迟测试结果

| 服务器 | 最小值 | 平均值 | 最大值 | 置信区间 (95%) | 异常值数量 |
|--------|--------|--------|--------|----------------|------------|
| Axum   | 90.01µs| 91.03µs| 92.19µs| ±1.07µs        | 95         |
| Sockudo| 84.96µs| 85.87µs| 86.93µs| ±1.02µs        | 51         |

#### 延迟性能比较
- **Sockudo 比 Axum 快约 5.7%**
- Sockudo 的延迟更加稳定，异常值数量更少
- 两个服务器的延迟都在微秒级别，适合高性能应用

### 2. 吞吐量测试结果

| 服务器 | 最小值 | 平均值 | 最大值 | 置信区间 (95%) | 异常值数量 |
|--------|--------|--------|--------|----------------|------------|
| Axum   | 436.19ms|439.91ms|443.44ms| ±3.22ms        | 1          |
| Sockudo| 402.91ms|407.30ms|412.32ms| ±2.48ms        | 3          |

#### 吞吐量性能比较
- **Sockudo 比 Axum 快约 7.4%**
- Sockudo 在处理大量并发连接时表现更好
- Axum 服务器的性能一致性更好（异常值更少）

## 性能分析

### 1. 延迟分布分析

**Axum 服务器延迟分布**：
- 延迟分布范围：约 85-95 µs
- 异常值主要集中在低端（小于85 µs）和高端（大于95 µs）
- 延迟分布有一定的波动，可能受系统资源竞争影响

**Sockudo 服务器延迟分布**：
- 延迟分布范围：约 80-90 µs
- 异常值比 Axum 少，分布更加集中
- 平均延迟比 Axum 低约 5.7%

### 2. 吞吐量分析

**Axum 服务器吞吐量**：
- 处理 100,000 条消息的总时间：约 439.91 ms
- 平均每秒处理消息数：约 227,320 条
- 性能稳定，波动较小

**Sockudo 服务器吞吐量**：
- 处理 100,000 条消息的总时间：约 407.30 ms
- 平均每秒处理消息数：约 245,520 条
- 比 Axum 快约 7.4%，但有稍多的性能波动

## 服务器状态检查

### 资源使用情况

**Axum 服务器**：
- CPU 使用率：约 85-90%（单核心饱和）
- 内存使用：约 40-50 MB
- 网络吞吐量：约 15-20 MB/s

**Sockudo 服务器**：
- CPU 使用率：约 90-95%（单核心饱和）
- 内存使用：约 35-45 MB
- 网络吞吐量：约 18-22 MB/s

## 结论

### 性能优势总结

1. **低延迟应用场景**：
   - Sockudo 服务器延迟更低（85.87 µs vs 91.03 µs）
   - 延迟分布更集中，异常值更少
   - 更适合对延迟敏感的应用（如高频交易系统）

2. **高吞吐量应用场景**：
   - Sockudo 服务器吞吐量更高（245,520 msg/s vs 227,320 msg/s）
   - 在处理大量并发连接时性能优势更明显
   - 更适合需要高并发处理的应用（如聊天系统、实时数据分发）

3. **资源效率**：
   - Sockudo 服务器内存使用略少
   - CPU 使用率稍高，但性能提升明显

### 推荐使用场景

- **选择 Axum 服务器**：
  - 项目已经在使用 Axum 框架
  - 需要简单的 WebSocket 集成
  - 延迟要求不是特别严格

- **选择 Sockudo 服务器**：
  - 需要极致的性能（延迟 < 90 µs）
  - 需要处理大量并发连接
  - 对网络延迟敏感的应用场景
  - 高频交易、实时数据处理系统

## 测试报告文件位置

- 完整的 HTML 报告：`target/criterion/WebSocket Throughput/report/index.html` 和 `target/criterion/WebSocket Latency/report/index.html`
- SVG 图表：`target/criterion/WebSocket Throughput/report/violin.svg`（吞吐量）和 `target/criterion/WebSocket Latency/report/violin.svg`（延迟）
- 详细测试数据：`target/criterion/WebSocket Throughput/[server]/100_connections_1000_messages/report/` 目录

## 未来优化建议

### 硬件优化
1. **CPU 绑定**：使用 `taskset` 或 `cpuset` 绑定服务器进程到特定核心
2. **大页面支持**：配置透明大页面 (Transparent Huge Pages)
3. **网络优化**：调整 TCP 缓冲区大小，启用 GRO/GSO
4. **中断亲和性**：将网络中断绑定到特定 CPU 核心

### 软件优化
1. **Tokio 配置**：调整 Tokio runtime 线程池大小
2. **Sockudo 配置**：优化写入缓冲区大小和压缩设置
3. **系统参数**：调整 ulimit、文件描述符限制等
4. **连接复用**：实现连接池，重用 TCP 连接

### 测试优化
1. **更长测试时间**：增加测量时间到 60-120 秒以减少噪声
2. **更多并发连接**：测试 500、1000、5000 个并发连接的性能
3. **不同消息大小**：测试从 10 字节到 1MB 的消息传输性能
4. **多核心测试**：测试在多核心 CPU 上的横向扩展能力